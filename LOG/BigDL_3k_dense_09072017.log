Using /opt/work/spark-2.1.0-bin-hadoop2.7
2017-09-07 20:17:58 INFO  SparkContext:54 - Running Spark version 2.1.0
2017-09-07 20:17:58 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2017-09-07 20:17:58 WARN  SparkConf:66 - 
SPARK_WORKER_INSTANCES was detected (set to '1').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --num-executors to specify the number of executors
 - Or set SPARK_EXECUTOR_INSTANCES
 - spark.executor.instances to configure the number of instances in the spark config.
        
2017-09-07 20:17:58 INFO  SecurityManager:54 - Changing view acls to: root
2017-09-07 20:17:58 INFO  SecurityManager:54 - Changing modify acls to: root
2017-09-07 20:17:58 INFO  SecurityManager:54 - Changing view acls groups to: 
2017-09-07 20:17:58 INFO  SecurityManager:54 - Changing modify acls groups to: 
2017-09-07 20:17:58 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2017-09-07 20:17:58 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 33859.
2017-09-07 20:17:58 INFO  SparkEnv:54 - Registering MapOutputTracker
2017-09-07 20:17:58 INFO  SparkEnv:54 - Registering BlockManagerMaster
2017-09-07 20:17:58 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2017-09-07 20:17:58 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2017-09-07 20:17:58 INFO  DiskBlockManager:54 - Created local directory at /dir1/scratch/spark/blockmgr-aa0ef233-f49e-40a7-9ce5-97ab936860f8
2017-09-07 20:17:58 INFO  MemoryStore:54 - MemoryStore started with capacity 95.8 GB
2017-09-07 20:17:59 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2017-09-07 20:17:59 INFO  log:186 - Logging initialized @2427ms
2017-09-07 20:17:59 INFO  Server:327 - jetty-9.2.z-SNAPSHOT
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@83123c3{/jobs,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5cae832b{/jobs/json,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@783aa6c3{/jobs/job,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6a762d6c{/jobs/job/json,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6b5834da{/stages,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@43c75541{/stages/json,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6ee6ef44{/stages/stage,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3520b2b9{/stages/stage/json,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@1f74be23{/stages/pool,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@66608dd1{/stages/pool/json,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@3fa5d296{/storage,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@fa01aa1{/storage/json,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@359f28d0{/storage/rdd,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@57f325b7{/storage/rdd/json,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@46d37cbd{/environment,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@492913d4{/environment/json,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@53c7b89{/executors,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4b2c3804{/executors/json,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@16c78348{/executors/threadDump,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@17f185f7{/executors/threadDump/json,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@71f744b3{/static,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@5bb1be91{/,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@7146bb6c{/api,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@6a83468e{/jobs/job/kill,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@219a55b1{/stages/stage/kill,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ServerConnector:266 - Started ServerConnector@22a63dc4{HTTP/1.1}{0.0.0.0:4040}
2017-09-07 20:17:59 INFO  Server:379 - Started @2565ms
2017-09-07 20:17:59 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2017-09-07 20:17:59 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://172.168.2.186:4040
2017-09-07 20:17:59 INFO  SparkContext:54 - Added JAR file:/root/BigDL-0.2.0/dist/lib/bigdl-0.2.0-jar-with-dependencies.jar at spark://172.168.2.186:33859/jars/bigdl-0.2.0-jar-with-dependencies.jar with timestamp 1504786679276
2017-09-07 20:17:59 INFO  SparkContext:54 - Added file file:/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py at file:/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py with timestamp 1504786679462
2017-09-07 20:17:59 INFO  Utils:54 - Copying /root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py to /dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/widedeep.py
2017-09-07 20:17:59 INFO  SparkContext:54 - Added file file:/root/BigDL-0.2.0/dist/lib/bigdl-0.2.0-python-api.zip at file:/root/BigDL-0.2.0/dist/lib/bigdl-0.2.0-python-api.zip with timestamp 1504786679476
2017-09-07 20:17:59 INFO  Utils:54 - Copying /root/BigDL-0.2.0/dist/lib/bigdl-0.2.0-python-api.zip to /dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip
2017-09-07 20:17:59 INFO  Executor:54 - Starting executor ID driver on host localhost
2017-09-07 20:17:59 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42619.
2017-09-07 20:17:59 INFO  NettyBlockTransferService:54 - Server created on 172.168.2.186:42619
2017-09-07 20:17:59 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2017-09-07 20:17:59 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 172.168.2.186, 42619, None)
2017-09-07 20:17:59 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 172.168.2.186:42619 with 95.8 GB RAM, BlockManagerId(driver, 172.168.2.186, 42619, None)
2017-09-07 20:17:59 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 172.168.2.186, 42619, None)
2017-09-07 20:17:59 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 172.168.2.186, 42619, None)
2017-09-07 20:17:59 INFO  ContextHandler:744 - Started o.s.j.s.ServletContextHandler@4ef4d3b3{/metrics/json,null,AVAILABLE}
2017-09-07 20:17:59 INFO  ThreadPool$:79 - Set mkl threads to 1 on thread 27
2017-09-07 20:17:59 INFO  Engine$:100 - Auto detect executor number and executor cores number
2017-09-07 20:17:59 INFO  Engine$:102 - Executor number is 1 and executor cores number is 24
2017-09-07 20:17:59 WARN  SparkContext:66 - Using an existing SparkContext; some configuration may not take effect.
2017-09-07 20:17:59 INFO  Engine$:291 - Find existing spark context. Checking the spark conf...
2017-09-07 20:18:00 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 299.9 KB, free 95.8 GB)
2017-09-07 20:18:00 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.9 KB, free 95.8 GB)
2017-09-07 20:18:00 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 172.168.2.186:42619 (size: 22.9 KB, free: 95.8 GB)
2017-09-07 20:18:00 INFO  SparkContext:54 - Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
2017-09-07 20:18:00 INFO  FileInputFormat:249 - Total input paths to process : 1
2017-09-07 20:18:00 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 300.0 KB, free 95.8 GB)
2017-09-07 20:18:00 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 22.9 KB, free 95.8 GB)
2017-09-07 20:18:00 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 172.168.2.186:42619 (size: 22.9 KB, free: 95.8 GB)
2017-09-07 20:18:00 INFO  SparkContext:54 - Created broadcast 1 from textFile at NativeMethodAccessorImpl.java:0
2017-09-07 20:18:00 INFO  FileInputFormat:249 - Total input paths to process : 1
creating: createSequential
creating: createConcat
creating: createSequential
creating: createNarrow
creating: createReshape
cls.getname: com.intel.analytics.bigdl.python.api.Sample
BigDLBasePickler registering: bigdl.util.common  Sample
cls.getname: com.intel.analytics.bigdl.python.api.TestResult
BigDLBasePickler registering: bigdl.util.common  TestResult
cls.getname: com.intel.analytics.bigdl.python.api.JTensor
BigDLBasePickler registering: bigdl.util.common  JTensor
creating: createSequential
creating: createNarrow
creating: createReshape
creating: createSequential
creating: createConcat
creating: createSequential
creating: createNarrow
creating: createReshape
creating: createSequential
creating: createSelect
creating: createLookupTable
creating: createSequential
creating: createSelect
creating: createLookupTable
creating: createSequential
creating: createNarrow
creating: createReshape
creating: createLinear
creating: createReLU
creating: createLinear
creating: createReLU
creating: createLinear
creating: createLogSoftMax
creating: createClassNLLCriterion
creating: createAdam
creating: createMaxEpoch
creating: createOptimizer
2017-09-07 20:18:01 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 128.0 B, free 95.8 GB)
2017-09-07 20:18:01 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 548.0 B, free 95.8 GB)
2017-09-07 20:18:01 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 172.168.2.186:42619 (size: 548.0 B, free: 95.8 GB)
2017-09-07 20:18:01 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DataSet.scala:169
disableCheckSingleton is deprecated. Please use bigdl.check.singleton instead
creating: createEveryEpoch
creating: createTop1Accuracy
creating: createClassNLLCriterion
creating: createLoss
2017-09-07 20:18:01 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 128.0 B, free 95.8 GB)
2017-09-07 20:18:01 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 548.0 B, free 95.8 GB)
2017-09-07 20:18:01 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 172.168.2.186:42619 (size: 548.0 B, free: 95.8 GB)
2017-09-07 20:18:01 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DataSet.scala:169
creating: createEveryEpoch
2017-09-07 20:18:01 INFO  DistriOptimizer$:717 - caching training rdd ...
2017-09-07 20:18:01 INFO  SparkContext:54 - Starting job: count at DataSet.scala:188
2017-09-07 20:18:01 INFO  DAGScheduler:54 - Registering RDD 13 (coalesce at DataSet.scala:358)
2017-09-07 20:18:01 INFO  DAGScheduler:54 - Got job 0 (count at DataSet.scala:188) with 1 output partitions
2017-09-07 20:18:01 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (count at DataSet.scala:188)
2017-09-07 20:18:01 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2017-09-07 20:18:01 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2017-09-07 20:18:01 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[13] at coalesce at DataSet.scala:358), which has no missing parents
2017-09-07 20:18:01 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 11.5 KB, free 95.8 GB)
2017-09-07 20:18:01 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 5.7 KB, free 95.8 GB)
2017-09-07 20:18:01 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 172.168.2.186:42619 (size: 5.7 KB, free: 95.8 GB)
2017-09-07 20:18:01 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:996
2017-09-07 20:18:01 INFO  DAGScheduler:54 - Submitting 10 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[13] at coalesce at DataSet.scala:358)
2017-09-07 20:18:01 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 10 tasks
2017-09-07 20:18:01 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6431 bytes)
2017-09-07 20:18:01 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 6431 bytes)
2017-09-07 20:18:01 INFO  TaskSetManager:54 - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 6431 bytes)
2017-09-07 20:18:01 INFO  TaskSetManager:54 - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 6431 bytes)
2017-09-07 20:18:01 INFO  TaskSetManager:54 - Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, PROCESS_LOCAL, 6431 bytes)
2017-09-07 20:18:01 INFO  TaskSetManager:54 - Starting task 5.0 in stage 0.0 (TID 5, localhost, executor driver, partition 5, PROCESS_LOCAL, 6431 bytes)
2017-09-07 20:18:01 INFO  TaskSetManager:54 - Starting task 6.0 in stage 0.0 (TID 6, localhost, executor driver, partition 6, PROCESS_LOCAL, 6431 bytes)
2017-09-07 20:18:01 INFO  TaskSetManager:54 - Starting task 7.0 in stage 0.0 (TID 7, localhost, executor driver, partition 7, PROCESS_LOCAL, 6431 bytes)
2017-09-07 20:18:01 INFO  TaskSetManager:54 - Starting task 8.0 in stage 0.0 (TID 8, localhost, executor driver, partition 8, PROCESS_LOCAL, 6431 bytes)
2017-09-07 20:18:01 INFO  TaskSetManager:54 - Starting task 9.0 in stage 0.0 (TID 9, localhost, executor driver, partition 9, PROCESS_LOCAL, 6431 bytes)
2017-09-07 20:18:01 INFO  Executor:54 - Running task 9.0 in stage 0.0 (TID 9)
2017-09-07 20:18:01 INFO  Executor:54 - Running task 1.0 in stage 0.0 (TID 1)
2017-09-07 20:18:01 INFO  Executor:54 - Running task 5.0 in stage 0.0 (TID 5)
2017-09-07 20:18:01 INFO  Executor:54 - Running task 3.0 in stage 0.0 (TID 3)
2017-09-07 20:18:01 INFO  Executor:54 - Running task 8.0 in stage 0.0 (TID 8)
2017-09-07 20:18:01 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2017-09-07 20:18:01 INFO  Executor:54 - Running task 2.0 in stage 0.0 (TID 2)
2017-09-07 20:18:01 INFO  Executor:54 - Running task 4.0 in stage 0.0 (TID 4)
2017-09-07 20:18:01 INFO  Executor:54 - Running task 6.0 in stage 0.0 (TID 6)
2017-09-07 20:18:01 INFO  Executor:54 - Running task 7.0 in stage 0.0 (TID 7)
2017-09-07 20:18:01 INFO  Executor:54 - Fetching file:/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py with timestamp 1504786679462
2017-09-07 20:18:01 INFO  Utils:54 - /root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py has been previously copied to /dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/widedeep.py
2017-09-07 20:18:01 INFO  Executor:54 - Fetching file:/root/BigDL-0.2.0/dist/lib/bigdl-0.2.0-python-api.zip with timestamp 1504786679476
2017-09-07 20:18:01 INFO  Utils:54 - /root/BigDL-0.2.0/dist/lib/bigdl-0.2.0-python-api.zip has been previously copied to /dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip
2017-09-07 20:18:01 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:301989888+26910692
2017-09-07 20:18:01 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:33554432+33554432
2017-09-07 20:18:01 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:67108864+33554432
2017-09-07 20:18:01 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:100663296+33554432
2017-09-07 20:18:01 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:234881024+33554432
2017-09-07 20:18:01 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:268435456+33554432
2017-09-07 20:18:01 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:201326592+33554432
2017-09-07 20:18:01 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:134217728+33554432
2017-09-07 20:18:01 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:167772160+33554432
2017-09-07 20:18:01 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:0+33554432
2017-09-07 20:18:01 INFO  deprecation:1173 - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2017-09-07 20:18:01 INFO  deprecation:1173 - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2017-09-07 20:18:01 INFO  deprecation:1173 - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2017-09-07 20:18:01 INFO  deprecation:1173 - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2017-09-07 20:18:01 INFO  deprecation:1173 - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2017-09-07 20:18:02 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:234881024+33554432
2017-09-07 20:18:02 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:167772160+33554432
2017-09-07 20:18:02 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:301989888+26910692
2017-09-07 20:18:02 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:0+33554432
2017-09-07 20:18:02 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:134217728+33554432
2017-09-07 20:18:02 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:201326592+33554432
2017-09-07 20:18:02 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:33554432+33554432
2017-09-07 20:18:02 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:268435456+33554432
2017-09-07 20:18:02 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:67108864+33554432
2017-09-07 20:18:02 INFO  HadoopRDD:54 - Input split: file:/root/BigDL-0.2.0/data/train_tensor.data:100663296+33554432
2017-09-07 20:18:02 ERROR Executor:91 - Exception in task 4.0 in stage 0.0 (TID 4)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py", line 82, in <lambda>
    Sample(features_label[0], features_label[1]+1, 3048, 1))
  File "/dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip/bigdl/util/common.py", line 198, in __init__
    self.features = np.array(features, dtype=get_dtype()).reshape(features_shape)  # noqa
ValueError: cannot reshape array of size 5046 into shape (3048,)

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2017-09-07 20:18:02 ERROR Executor:91 - Exception in task 7.0 in stage 0.0 (TID 7)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py", line 82, in <lambda>
    Sample(features_label[0], features_label[1]+1, 3048, 1))
  File "/dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip/bigdl/util/common.py", line 198, in __init__
    self.features = np.array(features, dtype=get_dtype()).reshape(features_shape)  # noqa
ValueError: cannot reshape array of size 5046 into shape (3048,)

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2017-09-07 20:18:02 WARN  TaskSetManager:66 - Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py", line 82, in <lambda>
    Sample(features_label[0], features_label[1]+1, 3048, 1))
  File "/dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip/bigdl/util/common.py", line 198, in __init__
    self.features = np.array(features, dtype=get_dtype()).reshape(features_shape)  # noqa
ValueError: cannot reshape array of size 5046 into shape (3048,)

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

2017-09-07 20:18:02 ERROR Executor:91 - Exception in task 8.0 in stage 0.0 (TID 8)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py", line 82, in <lambda>
    Sample(features_label[0], features_label[1]+1, 3048, 1))
  File "/dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip/bigdl/util/common.py", line 198, in __init__
    self.features = np.array(features, dtype=get_dtype()).reshape(features_shape)  # noqa
ValueError: cannot reshape array of size 5046 into shape (3048,)

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2017-09-07 20:18:02 ERROR TaskSetManager:70 - Task 4 in stage 0.0 failed 1 times; aborting job
2017-09-07 20:18:02 INFO  TaskSetManager:54 - Lost task 7.0 in stage 0.0 (TID 7) on localhost, executor driver: org.apache.spark.api.python.PythonException (Traceback (most recent call last):
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py", line 82, in <lambda>
    Sample(features_label[0], features_label[1]+1, 3048, 1))
  File "/dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip/bigdl/util/common.py", line 198, in __init__
    self.features = np.array(features, dtype=get_dtype()).reshape(features_shape)  # noqa
ValueError: cannot reshape array of size 5046 into shape (3048,)
) [duplicate 1]
2017-09-07 20:18:02 INFO  TaskSetManager:54 - Lost task 8.0 in stage 0.0 (TID 8) on localhost, executor driver: org.apache.spark.api.python.PythonException (Traceback (most recent call last):
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py", line 82, in <lambda>
    Sample(features_label[0], features_label[1]+1, 3048, 1))
  File "/dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip/bigdl/util/common.py", line 198, in __init__
    self.features = np.array(features, dtype=get_dtype()).reshape(features_shape)  # noqa
ValueError: cannot reshape array of size 5046 into shape (3048,)
) [duplicate 2]
2017-09-07 20:18:02 ERROR Executor:91 - Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py", line 82, in <lambda>
    Sample(features_label[0], features_label[1]+1, 3048, 1))
  File "/dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip/bigdl/util/common.py", line 198, in __init__
    self.features = np.array(features, dtype=get_dtype()).reshape(features_shape)  # noqa
ValueError: cannot reshape array of size 5046 into shape (3048,)

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2017-09-07 20:18:02 ERROR Executor:91 - Exception in task 9.0 in stage 0.0 (TID 9)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py", line 82, in <lambda>
    Sample(features_label[0], features_label[1]+1, 3048, 1))
  File "/dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip/bigdl/util/common.py", line 198, in __init__
    self.features = np.array(features, dtype=get_dtype()).reshape(features_shape)  # noqa
ValueError: cannot reshape array of size 5046 into shape (3048,)

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2017-09-07 20:18:02 ERROR Executor:91 - Exception in task 6.0 in stage 0.0 (TID 6)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py", line 82, in <lambda>
    Sample(features_label[0], features_label[1]+1, 3048, 1))
  File "/dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip/bigdl/util/common.py", line 198, in __init__
    self.features = np.array(features, dtype=get_dtype()).reshape(features_shape)  # noqa
ValueError: cannot reshape array of size 5046 into shape (3048,)

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2017-09-07 20:18:02 INFO  TaskSetManager:54 - Lost task 0.0 in stage 0.0 (TID 0) on localhost, executor driver: org.apache.spark.api.python.PythonException (Traceback (most recent call last):
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py", line 82, in <lambda>
    Sample(features_label[0], features_label[1]+1, 3048, 1))
  File "/dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip/bigdl/util/common.py", line 198, in __init__
    self.features = np.array(features, dtype=get_dtype()).reshape(features_shape)  # noqa
ValueError: cannot reshape array of size 5046 into shape (3048,)
) [duplicate 3]
2017-09-07 20:18:02 INFO  TaskSchedulerImpl:54 - Cancelling stage 0
2017-09-07 20:18:02 ERROR Executor:91 - Exception in task 5.0 in stage 0.0 (TID 5)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py", line 82, in <lambda>
    Sample(features_label[0], features_label[1]+1, 3048, 1))
  File "/dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip/bigdl/util/common.py", line 198, in __init__
    self.features = np.array(features, dtype=get_dtype()).reshape(features_shape)  # noqa
ValueError: cannot reshape array of size 5046 into shape (3048,)

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2017-09-07 20:18:02 INFO  TaskSchedulerImpl:54 - Stage 0 was cancelled
2017-09-07 20:18:02 INFO  TaskSetManager:54 - Lost task 9.0 in stage 0.0 (TID 9) on localhost, executor driver: org.apache.spark.api.python.PythonException (Traceback (most recent call last):
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py", line 82, in <lambda>
    Sample(features_label[0], features_label[1]+1, 3048, 1))
  File "/dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip/bigdl/util/common.py", line 198, in __init__
    self.features = np.array(features, dtype=get_dtype()).reshape(features_shape)  # noqa
ValueError: cannot reshape array of size 5046 into shape (3048,)
) [duplicate 4]
2017-09-07 20:18:02 INFO  DAGScheduler:54 - ShuffleMapStage 0 (coalesce at DataSet.scala:358) failed in 1.559 s due to Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py", line 82, in <lambda>
    Sample(features_label[0], features_label[1]+1, 3048, 1))
  File "/dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip/bigdl/util/common.py", line 198, in __init__
    self.features = np.array(features, dtype=get_dtype()).reshape(features_shape)  # noqa
ValueError: cannot reshape array of size 5046 into shape (3048,)

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
2017-09-07 20:18:02 INFO  TaskSetManager:54 - Lost task 6.0 in stage 0.0 (TID 6) on localhost, executor driver: org.apache.spark.api.python.PythonException (Traceback (most recent call last):
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py", line 82, in <lambda>
    Sample(features_label[0], features_label[1]+1, 3048, 1))
  File "/dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip/bigdl/util/common.py", line 198, in __init__
    self.features = np.array(features, dtype=get_dtype()).reshape(features_shape)  # noqa
ValueError: cannot reshape array of size 5046 into shape (3048,)
) [duplicate 5]
2017-09-07 20:18:02 INFO  TaskSetManager:54 - Lost task 5.0 in stage 0.0 (TID 5) on localhost, executor driver: org.apache.spark.api.python.PythonException (Traceback (most recent call last):
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py", line 82, in <lambda>
    Sample(features_label[0], features_label[1]+1, 3048, 1))
  File "/dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip/bigdl/util/common.py", line 198, in __init__
    self.features = np.array(features, dtype=get_dtype()).reshape(features_shape)  # noqa
ValueError: cannot reshape array of size 5046 into shape (3048,)
) [duplicate 6]
2017-09-07 20:18:02 INFO  Executor:54 - Executor is trying to kill task 1.0 in stage 0.0 (TID 1)
2017-09-07 20:18:02 INFO  Executor:54 - Executor is trying to kill task 2.0 in stage 0.0 (TID 2)
2017-09-07 20:18:02 INFO  Executor:54 - Executor is trying to kill task 3.0 in stage 0.0 (TID 3)
2017-09-07 20:18:02 INFO  DAGScheduler:54 - Job 0 failed: count at DataSet.scala:188, took 1.720640 s
Traceback (most recent call last):
  File "/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py", line 121, in <module>
    trained_model = optimizer.optimize()
  File "/root/BigDL-0.2.0/dist/lib/bigdl-0.2.0-python-api.zip/bigdl/optim/optimizer.py", line 569, in optimize
  File "/root/BigDL-0.2.0/dist/lib/bigdl-0.2.0-python-api.zip/bigdl/util/common.py", line 345, in callJavaFunc
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py", line 1133, in __call__
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py", line 319, in get_return_value
py4j.protocol.Py4JJavaError2017-09-07 20:18:02 INFO  Executor:54 - Executor killed task 3.0 in stage 0.0 (TID 3)
2017-09-07 20:18:02 INFO  Executor:54 - Executor killed task 1.0 in stage 0.0 (TID 1)
2017-09-07 20:18:02 INFO  Executor:54 - Executor killed task 2.0 in stage 0.0 (TID 2)
: An error occurred while calling o168.optimize.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 0.0 failed 1 times, most recent failure: Lost task 4.0 in stage 0.0 (TID 4, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py", line 82, in <lambda>
    Sample(features_label[0], features_label[1]+1, 3048, 1))
  File "/dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip/bigdl/util/common.py", line 198, in __init__
    self.features = np.array(features, dtype=get_dtype()).reshape(features_shape)  # noqa
ValueError: cannot reshape array of size 5046 into shape (3048,)

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1958)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1157)
	at com.intel.analytics.bigdl.dataset.DistributedDataSet$$anon$5.cache(DataSet.scala:188)
	at com.intel.analytics.bigdl.optim.DistriOptimizer.prepareInput(DistriOptimizer.scala:718)
	at com.intel.analytics.bigdl.optim.DistriOptimizer.optimize(DistriOptimizer.scala:738)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/work/spark-2.1.0-bin-hadoop2.7/python/lib/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/root/BigDL-0.2.0/pyspark/bigdl/models/widedeep/widedeep.py", line 82, in <lambda>
    Sample(features_label[0], features_label[1]+1, 3048, 1))
  File "/dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/userFiles-ceed438a-3992-46ec-a1c5-0e5f91c278fc/bigdl-0.2.0-python-api.zip/bigdl/util/common.py", line 198, in __init__
    self.features = np.array(features, dtype=get_dtype()).reshape(features_shape)  # noqa
ValueError: cannot reshape array of size 5046 into shape (3048,)

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more

2017-09-07 20:18:02 WARN  TaskSetManager:66 - Lost task 1.0 in stage 0.0 (TID 1, localhost, executor driver): TaskKilled (killed intentionally)
2017-09-07 20:18:02 WARN  TaskSetManager:66 - Lost task 3.0 in stage 0.0 (TID 3, localhost, executor driver): TaskKilled (killed intentionally)
2017-09-07 20:18:02 WARN  TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 2, localhost, executor driver): TaskKilled (killed intentionally)
2017-09-07 20:18:02 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2017-09-07 20:18:02 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2017-09-07 20:18:02 INFO  ServerConnector:306 - Stopped ServerConnector@22a63dc4{HTTP/1.1}{0.0.0.0:4040}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@219a55b1{/stages/stage/kill,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6a83468e{/jobs/job/kill,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@7146bb6c{/api,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5bb1be91{/,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@71f744b3{/static,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@17f185f7{/executors/threadDump/json,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@16c78348{/executors/threadDump,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@4b2c3804{/executors/json,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@53c7b89{/executors,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@492913d4{/environment/json,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@46d37cbd{/environment,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@57f325b7{/storage/rdd/json,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@359f28d0{/storage/rdd,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@fa01aa1{/storage/json,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3fa5d296{/storage,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@66608dd1{/stages/pool/json,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@1f74be23{/stages/pool,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@3520b2b9{/stages/stage/json,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6ee6ef44{/stages/stage,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@43c75541{/stages/json,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6b5834da{/stages,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@6a762d6c{/jobs/job/json,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@783aa6c3{/jobs/job,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@5cae832b{/jobs/json,null,UNAVAILABLE}
2017-09-07 20:18:02 INFO  ContextHandler:865 - Stopped o.s.j.s.ServletContextHandler@83123c3{/jobs,null,UNAVAILABLE}
2017-09-07 20:18:03 INFO  SparkUI:54 - Stopped Spark web UI at http://172.168.2.186:4040
2017-09-07 20:18:03 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2017-09-07 20:18:03 INFO  MemoryStore:54 - MemoryStore cleared
2017-09-07 20:18:03 INFO  BlockManager:54 - BlockManager stopped
2017-09-07 20:18:03 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2017-09-07 20:18:03 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2017-09-07 20:18:03 INFO  SparkContext:54 - Successfully stopped SparkContext
2017-09-07 20:18:03 INFO  ShutdownHookManager:54 - Shutdown hook called
2017-09-07 20:18:03 INFO  ShutdownHookManager:54 - Deleting directory /dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4/pyspark-258ecce2-9f10-4435-b076-8a00b1d68827
2017-09-07 20:18:03 INFO  ShutdownHookManager:54 - Deleting directory /dir1/scratch/spark/spark-f8f7f227-9f0d-42d4-a4a5-c91d856e9ee4
